{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySuZ_7Li_PxX"
   },
   "source": [
    "‰∏Ä„ÄÅDataset ÁöÑÊÑè‰πâ‰∏éÂ∏∏Áî®ÂÜôÊ≥ï\n",
    "üìå ‰ΩúÁî®\n",
    "\n",
    "Dataset ÊòØ‰Ω†ÂØπÊï∞ÊçÆÈõÜÁöÑÊäΩË±°Â∞ÅË£ÖÔºåÂÆÉÂÆö‰πâ‰∫ÜÔºö\n",
    "\n",
    "- Êï∞ÊçÆÈõÜÊúâÂ§öÂ∞ëÊù°Ôºà**len**Ôºâ\n",
    "\n",
    "- ÊØè‰∏ÄÊù°Êï∞ÊçÆÂ¶Ç‰ΩïË¢´ËØªÂèñ‰∏éÈ¢ÑÂ§ÑÁêÜÔºà**getitem**Ôºâ\n",
    "\n",
    "ÂèØ‰ª•Áî®ÂÆÉÊù•Â∞ÅË£ÖÂõæÁâá„ÄÅÊñáÊú¨„ÄÅCSV Ë°®Ê†º„ÄÅÊï∞ÊçÆÂ∫ìÁ≠âÂêÑÁßçÂΩ¢ÂºèÁöÑÊï∞ÊçÆ„ÄÇ\n",
    "\n",
    "Â∏∏ËßÅ‰ΩøÁî®Âú∫ÊôØ\n",
    "\n",
    "Ëá™ÂÆö‰πâÊï∞ÊçÆÈõÜÔºàÂ¶ÇÊú¨Âú∞ÂõæÁâáÂàÜÁ±ªÔºâ\n",
    "\n",
    "Âä†ËΩΩÊ†áÂáÜÊï∞ÊçÆÈõÜÔºàÂ¶Ç torchvision.datasets.MNISTÔºâ\n",
    "\n",
    "Âú® **getitem** ÈáåÂÅöÈ¢ÑÂ§ÑÁêÜÔºàÂ¶Ç resize„ÄÅtokenize„ÄÅÊ†áÂáÜÂåñÁ≠âÔºâ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UW2UpJ6J_JMp"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data  # ÂèØ‰ª•ÊòØnumpyÊï∞ÁªÑ„ÄÅÂàóË°®Á≠â\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)  # ËøîÂõûÊ†∑Êú¨Êï∞Èáè\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx]\n",
    "        y = self.labels[idx]\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1758973559133,
     "user": {
      "displayName": "Vu Dang",
      "userId": "15007056265375921362"
     },
     "user_tz": -480
    },
    "id": "AoU-hgFv_kJt",
    "outputId": "2a5019ea-1273-4d95-9198-c3224d533ad2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "([1, 2], 0)\n"
     ]
    }
   ],
   "source": [
    "dataset = MyDataset(data=[[1, 2], [3, 4]], labels=[0, 1])\n",
    "print(len(dataset))  # 2\n",
    "print(dataset[0])  # ([1,2], 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WiRJa4IQ_1hb"
   },
   "source": [
    "‰∫å„ÄÅDataLoader ÁöÑÊÑè‰πâ‰∏éÂ∏∏Áî®ÂÜôÊ≥ï\n",
    "üìå ‰ΩúÁî®\n",
    "\n",
    "DataLoader ÊòØÂØπ Dataset ÁöÑËøõ‰∏ÄÊ≠•Â∞ÅË£ÖÔºåÂÆÉÊèê‰æõÔºö\n",
    "\n",
    "- Ëá™Âä®Êåâ batch ÂàÜÁªÑ\n",
    "\n",
    "- Ëá™Âä® shuffle Êâì‰π±\n",
    "\n",
    "- Â§öËøõÁ®ãÂπ∂Ë°åÂä†ËΩΩÔºànum_workersÔºâ\n",
    "\n",
    "- Êåâ epoch Âæ™ÁéØËø≠‰ª£\n",
    "\n",
    "ÂÆÉËøîÂõûÁöÑÊòØ‰∏Ä‰∏™**ÂèØËø≠‰ª£ÂØπË±°**ÔºåÊØèÊ¨°Ëø≠‰ª£ËøîÂõû‰∏Ä‰∏™ batch„ÄÇ\n",
    "\n",
    "Â∏∏Áî®ÂèÇÊï∞Ôºö\n",
    "\n",
    "| ÂèÇÊï∞Âêç        | ‰ΩúÁî®                                                        |\n",
    "| ------------- | ----------------------------------------------------------- |\n",
    "| `batch_size`  | ÊØè‰∏™ batch ÈáåÊúâÂ§öÂ∞ëÊ†∑Êú¨                                     |\n",
    "| `shuffle`     | ÊØè‰∏™ epoch ÊòØÂê¶Êâì‰π±Êï∞ÊçÆ                                     |\n",
    "| `num_workers` | Êï∞ÊçÆÂä†ËΩΩ‰ΩøÁî®ÁöÑÂ≠êËøõÁ®ãÊï∞Ôºà>0 ÂèØ‰ª•Âä†ÈÄüÔºâ                       |\n",
    "| `drop_last`   | ÂΩìÊï∞ÊçÆ‰∏çËÉΩÊï¥Èô§ batch_size Êó∂ÊòØÂê¶‰∏¢ÂºÉÊúÄÂêé‰∏ÄÊâπ                |\n",
    "| `collate_fn`  | Ëá™ÂÆö‰πâ batch ÂêàÂπ∂ÊñπÂºèÔºàÈªòËÆ§ÊåâÁÖßÁ¥¢Âºï‰ΩçÁΩÆÂàÜÁ±ªËøîÂõûÔºâ           |\n",
    "| `pin_memory`  | Â∞ÜÊï∞ÊçÆÁõ¥Êé•ÂÜôÂÖ• GPU ‰ªéÂÜÖÂ≠òËØªÂèñÊï∞ÊçÆÁöÑ‰ΩçÁΩÆÔºåÈÅøÂÖç‰∏≠Èó¥ÁöÑËΩ¨ÂåñÊ≠•È™§ |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1758980250196,
     "user": {
      "displayName": "Vu Dang",
      "userId": "15007056265375921362"
     },
     "user_tz": -480
    },
    "id": "JOEmdSllAux_",
    "outputId": "fca7188c-8ded-474a-d9b9-93a415289fc0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0, 0), (1, 1, 1), (2, 4, 8), (3, 9, 27), (4, 16, 64)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data = [(x, x**2, x**3) for x in range(5)]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 108,
     "status": "ok",
     "timestamp": 1758980477778,
     "user": {
      "displayName": "Vu Dang",
      "userId": "15007056265375921362"
     },
     "user_tz": -480
    },
    "id": "ZLYX3tXUBBSb",
    "outputId": "662c7a97-afbb-474c-84b7-f73790660e37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‰º†ÂÖ•Êï∞ÊçÆÊòØ: [(4, 16, 64), (0, 0, 0)]\n",
      "(((4, 0), (16, 0)), (64, 0))\n",
      "‰º†ÂÖ•Êï∞ÊçÆÊòØ: [(1, 1, 1), (3, 9, 27)]\n",
      "(((1, 3), (1, 9)), (1, 27))\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "\n",
    "def collate_fn(data):\n",
    "    print(\"‰º†ÂÖ•Êï∞ÊçÆÊòØ:\", data)\n",
    "    x, y, z = zip(*data)\n",
    "    return (x, y), z\n",
    "\n",
    "\n",
    "loader = DataLoader(\n",
    "    data, batch_size=2, shuffle=True, drop_last=True, collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "\n",
    "# Ëá™Âä®ËΩ¨Âåñ‰∏∫ tensor Âπ∂ÊåâÁÖß Á¥¢Âºï‰ΩçÁΩÆÂàÜÁ±ªËøîÂõû(x, y)\n",
    "for batch in loader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "xPQFSB5cABft"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([3, 0]), tensor([9, 0]), tensor([27,  0])]\n",
      "[tensor([4, 2]), tensor([16,  4]), tensor([64,  8])]\n",
      "[tensor([1]), tensor([1]), tensor([1])]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ÂÖ∂‰∏≠ÁöÑ dataset Âè™Ë¶ÅÂÆûÁé∞‰∫Ü __len__ & __getitem__ Â∞±Ë°å\n",
    "loader = DataLoader(\n",
    "    data,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    num_workers=0,  # Â§öÁ∫øÁ®ãÊï∞ÊçÆÂä†ËΩΩ\n",
    ")\n",
    "\n",
    "for batch in loader:\n",
    "    print(batch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2aBt7_RxAezX"
   },
   "source": [
    "| È°πÁõÆ         | Dataset                      | DataLoader                     |\n",
    "| ------------ | ---------------------------- | ------------------------------ |\n",
    "| ÂäüËÉΩ         | ÂÆö‰πâÊï∞ÊçÆÁöÑËÆøÈóÆÊñπÂºè           | ÊéßÂà∂ÊâπÈáèËØªÂèñ„ÄÅÊâì‰π±„ÄÅÂπ∂Ë°åÂä†ËΩΩ   |\n",
    "| ÂøÖÈ°ªÂÆûÁé∞ÊñπÊ≥ï | `__len__`, `__getitem__`     | ‰∏çÈúÄË¶ÅËá™Â∑±ÂÆö‰πâÔºåÁõ¥Êé•‰º† Dataset |\n",
    "| ‰∏ªË¶ÅÁî®ÈÄî     | ÊäΩË±°ÂéüÂßãÊï∞ÊçÆÔºàÊñπ‰æøÁÆ°ÁêÜÔºâ     | È´òÊïàËø≠‰ª£ÔºåËá™Âä®ÊâπÂ§ÑÁêÜ           |\n",
    "| È´òÁ∫ßÁî®Ê≥ï     | Ëá™ÂÆö‰πâÂèñÊ†∑Á≠ñÁï•„ÄÅÂä®ÊÄÅÊï∞ÊçÆÂ¢ûÂº∫ | Ëá™ÂÆö‰πâ collate_fn„ÄÅÂºÇÊ≠•È¢ÑÂèñÁ≠â  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aHgYQ_fEIxJm"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- 0) ÊûÑÈÄ†‰∏Ä‰∏™Á§∫‰æã DataFrame\n",
    "rng = np.random.default_rng(0)\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"age\": rng.integers(18, 60, size=1000),\n",
    "        \"income\": rng.normal(10_000, 3_000, size=1000),\n",
    "        \"city\": rng.choice([\"SH\", \"BJ\", \"SZ\"], size=1000),\n",
    "        \"is_vip\": rng.choice([0, 1], size=1000, p=[0.7, 0.3]),  # ‰Ωú‰∏∫ÂàÜÁ±ªÊ†áÁ≠æ\n",
    "    }\n",
    ")\n",
    "\n",
    "# --- 1) ÂàóÂàíÂàÜ & È¢ÑÂ§ÑÁêÜÔºàDataFrame -> Á∫ØÊï∞ÂÄºÁü©ÈòµÔºâ\n",
    "num_cols = [\"age\", \"income\"]\n",
    "cat_cols = [\"city\"]\n",
    "label_col = \"is_vip\"\n",
    "\n",
    "# ÂàáÂàÜÊï∞ÊçÆ\n",
    "train_df, val_df = train_test_split(\n",
    "    df, test_size=0.2, random_state=42, stratify=df[label_col]\n",
    ")\n",
    "\n",
    "# Êï∞ÂÄºÂàóÔºöÊ†áÂáÜÂåñÔºàfit on train, transform on bothÔºâ\n",
    "scaler = StandardScaler()\n",
    "X_train_num = scaler.fit_transform(train_df[num_cols].astype(\"float32\"))\n",
    "X_val_num = scaler.transform(val_df[num_cols].astype(\"float32\"))\n",
    "\n",
    "# Á±ªÂà´ÂàóÔºöone-hotÔºàÁî® pandas ÊØî OneHotEncoder ÁâàÊú¨Â∑ÆÂºÇÊõ¥Â∞ëÔºâ\n",
    "X_train_cat = pd.get_dummies(train_df[cat_cols], dummy_na=True)\n",
    "X_val_cat = pd.get_dummies(val_df[cat_cols], dummy_na=True)\n",
    "\n",
    "# ÂØπÈΩê one-hot ÂàóÔºàÈò≤Ê≠¢È™åËØÅÈõÜÁº∫Â∞ëÊüê‰∫õÁ±ªÂà´ÂØºËá¥Âàó‰∏çÈΩêÔºâ\n",
    "X_val_cat = X_val_cat.reindex(columns=X_train_cat.columns, fill_value=0)\n",
    "\n",
    "# ÂêàÂπ∂‰∏∫ÊúÄÁªàÁâπÂæÅÁü©ÈòµÔºànp.float32Ôºâ\n",
    "X_train = np.hstack([X_train_num, X_train_cat.to_numpy(dtype=np.float32)]).astype(\n",
    "    \"float32\"\n",
    ")\n",
    "X_val = np.hstack([X_val_num, X_val_cat.to_numpy(dtype=np.float32)]).astype(\"float32\")\n",
    "\n",
    "y_train = train_df[label_col].to_numpy(dtype=np.int64)  # CrossEntropyLoss ÊúüÊúõ long\n",
    "y_val = val_df[label_col].to_numpy(dtype=np.int64)\n",
    "\n",
    "\n",
    "# --- 2) ÂÆö‰πâ DatasetÔºö‰∏ÄÊ¨°ÊÄßÊää numpy -> tensorÔºàÈÅøÂÖç __getitem__ ÈáçÂ§çËΩ¨Êç¢Ôºâ\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray):\n",
    "        assert X.shape[0] == y.shape[0]\n",
    "        # ÊèêÂâçËΩ¨Êàê tensorÔºàÊÄßËÉΩÂèãÂ•ΩÔºâÔºöÂè™ÂÅö‰∏ÄÊ¨°Êã∑Ë¥ù/Á±ªÂûãËΩ¨Êç¢\n",
    "        self.X = torch.from_numpy(X).to(torch.float32)  # [N, D]\n",
    "        self.y = torch.from_numpy(y).to(torch.long)  # [N]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "train_ds = TabularDataset(X_train, y_train)\n",
    "val_ds = TabularDataset(X_val, y_val)\n",
    "\n",
    "# --- 3) DataLoaderÔºöÊâπÈáè„ÄÅÊâì‰π±„ÄÅÂπ∂Ë°åÈ¢ÑÂèñ„ÄÅÈ°µÈîÅÂÆöÂÜÖÂ≠ò\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=256,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "\n",
    "# --- 4) ‰∏Ä‰∏™ÊúÄÂ∞èÂèØË∑ëÁöÑÊ®°Âûã+ËÆ≠ÁªÉ/È™åËØÅÂæ™ÁéØÔºàÊºîÁ§∫ CPU->GPU È´òÊïàÊê¨ËøêÔºâ\n",
    "model = nn.Sequential(nn.Linear(X_train.shape[1], 64), nn.ReLU(), nn.Linear(64, 2)).to(\n",
    "    device\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(3):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for xb, yb in train_loader:\n",
    "        xb = xb.to(device, non_blocking=True)  # ÈÖçÂêà pin_memory=True\n",
    "        yb = yb.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * xb.size(0)\n",
    "\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.inference_mode():\n",
    "        for xb, yb in val_loader:\n",
    "            xb = xb.to(device, non_blocking=True)\n",
    "            yb = yb.to(device, non_blocking=True)\n",
    "            pred = model(xb).argmax(dim=1)\n",
    "            correct += (pred == yb).sum().item()\n",
    "            total += yb.size(0)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch + 1} | train_loss={running_loss / len(train_ds):.4f} \"\n",
    "        f\"| val_acc={correct / total:.3f}\"\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyONmMpKEeGgxmETR3BZw7NX",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
